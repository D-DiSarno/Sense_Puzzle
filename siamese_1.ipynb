{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.215759Z",
     "start_time": "2024-01-17T17:06:12.155729Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from itertools import islice\n",
    "from Bio import pairwise2\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import time\n",
    "import csv\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.235981Z",
     "start_time": "2024-01-17T17:06:12.172385Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "CUDA_FLAG = torch.cuda.is_available()\n",
    "print(CUDA_FLAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.236599Z",
     "start_time": "2024-01-17T17:06:12.179491Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.236923Z",
     "start_time": "2024-01-17T17:06:12.186014Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "if CUDA_FLAG:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "SEQ_LEN =465#provare 100\n",
    "EMBEDDING_LEN = 120#50\n",
    "NUM_TRAINING_PAIRS = 50 * 500\n",
    "NUM_EPOCH = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "class Config():\n",
    "    train_data_fp = './demo/pair_shuffle.fa'\n",
    "    train_target_fp = './demo/dist_shuffle.txt'\n",
    "    train_num_example = NUM_TRAINING_PAIRS\n",
    "    train_batch_size = BATCH_SIZE\n",
    "    num_epoch = NUM_EPOCH\n",
    "    learning_rate =LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.237170Z",
     "start_time": "2024-01-17T17:06:12.201365Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class MaxMinout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, embedding1, embedding2):\n",
    "        shape = list(embedding1.size())\n",
    "        flat1 = embedding1.view(1, -1)\n",
    "        flat2 = embedding2.view(1, -1)\n",
    "        combined = torch.cat((flat1, flat2), 0)\n",
    "        maxout = combined.max(0)[0].view(*shape)\n",
    "        # minout = combined.min(0)[0].view(*shape)\n",
    "        minout = ((combined * -1).max(0)[0].view(*shape) * -1) # workaround for memory leak bug\n",
    "\n",
    "        return maxout, minout\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.maxminout = MaxMinout()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(4, 16, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(),\n",
    "                \n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(),\n",
    "               \n",
    "            nn.Conv1d(32, 48, kernel_size=5, padding=2),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        max_pooling_len = SEQ_LEN \n",
    "        max_pooling_len = np.floor((max_pooling_len - 2) / 2 + 1)\n",
    "        max_pooling_len = np.floor((max_pooling_len - 2) / 2 + 1)\n",
    "        max_pooling_len = np.floor((max_pooling_len - 2) / 2 + 1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(int(48 * max_pooling_len), EMBEDDING_LEN),\n",
    "        )\n",
    "\n",
    "    def forward_one_side(self, x):\n",
    "        output = self.cnn(x)\n",
    "        output = output.view(output.size()[0], -1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        embedding1 = self.forward_one_side(input1)\n",
    "        embedding2 = self.forward_one_side(input2)\n",
    "        maxout, minout = self.maxminout(embedding1, embedding2)\n",
    "        return maxout, minout\n",
    "  \n",
    "\n",
    "\n",
    "    def align_sequences(self, seq1_embedding, seq2_embedding):\n",
    "        maxout, minout = self.maxminout(seq1_embedding, seq2_embedding)\n",
    "        return maxout, minout\n",
    "\n",
    "    def get_embedding(self, sequence):\n",
    "        seq_tensor = torch.zeros((1, 4, SEQ_LEN))\n",
    "\n",
    "        for i, c in enumerate(sequence):\n",
    "            seq_tensor[0, atcg_map.get(c, 0), i] = 1.0\n",
    "\n",
    "        if CUDA_FLAG:\n",
    "            seq_tensor = seq_tensor.cuda()\n",
    "\n",
    "        seq_tensor = Variable(seq_tensor)\n",
    "        embedding = self.forward_one_side(seq_tensor)\n",
    "\n",
    "        return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.237389Z",
     "start_time": "2024-01-17T17:06:12.209993Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def weight_func(dist):\n",
    "    return 1.0\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, maxout, minout, align_dist):\n",
    "        weight = Variable(torch.FloatTensor([weight_func(x) for x in align_dist.data]), requires_grad=False)\n",
    "        if CUDA_FLAG:\n",
    "            weight = weight.cuda()\n",
    "        loss_contrastive = torch.mean(torch.mul(weight, torch.pow(1 - minout.sum(1)/maxout.sum(1) - align_dist, 2)))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-17T17:06:12.238349Z",
     "start_time": "2024-01-17T17:06:12.220870Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "atcg_map = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "\n",
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self, data_fp, target_fp, N):\n",
    "        self.data_fp = data_fp\n",
    "        self.target_fp = target_fp\n",
    "        self.N = N\n",
    "        self.data_tensor = self.gen_data_tensor()\n",
    "        self.target_tensor = self.gen_target_tensor()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data_tensor[0][index], self.data_tensor[1][index], self.target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.N\n",
    "    \n",
    "    def gen_data_tensor (self):\n",
    "        seq1 = torch.zeros((self.N, 4, SEQ_LEN))\n",
    "        seq2 = torch.zeros((self.N, 4, SEQ_LEN))\n",
    "        cnt = 0\n",
    "        with open(self.data_fp) as f:\n",
    "            while True:\n",
    "                next_n = list(islice(f, 4))\n",
    "                if not next_n:\n",
    "                    break\n",
    "                if cnt >= self.N:\n",
    "                    break\n",
    "                read1 = next_n[1].strip()\n",
    "                read2 = next_n[3].strip()\n",
    "                for i, c in enumerate(read1):\n",
    "                    seq1[cnt, atcg_map.get(c, 0), i] = 1.0\n",
    "                for i, c in enumerate(read2):\n",
    "                    seq2[cnt, atcg_map.get(c, 0), i] = 1.0\n",
    "                cnt += 1\n",
    "        return seq1, seq2\n",
    "\n",
    "    def gen_target_tensor(self):\n",
    "        target = torch.zeros(self.N)\n",
    "        with open(self.target_fp) as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= self.N:\n",
    "                    break\n",
    "                pair_id, dist = line.strip().split()\n",
    "                target[i] = float(dist)\n",
    "        return target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-17T17:06:12.230801Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "net = SiameseNetwork()    \n",
    "if CUDA_FLAG:\n",
    "    net.cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=Config.learning_rate, weight_decay=0)\n",
    "print(net)\n",
    "\n",
    "training_dataset = SiameseNetworkDataset(Config.train_data_fp, \n",
    "                                         Config.train_target_fp,\n",
    "                                         Config.train_num_example)\n",
    "\n",
    "training_loader = DataLoader(\n",
    "    dataset=training_dataset,      \n",
    "    batch_size=Config.train_batch_size,      \n",
    "    shuffle=True,              \n",
    "    num_workers=0,#4              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_num_batch = int(np.ceil(Config.train_num_example / Config.train_batch_size))\n",
    "train_batch_interval = Config.train_num_example // Config.train_batch_size // 10\n",
    "train_loss_hist = []\n",
    "\n",
    "for epoch in range(Config.num_epoch):\n",
    "    print('===========>')\n",
    "    train_running_loss = 0\n",
    "    for batch_index, (train_seq1, train_seq2, train_target) in enumerate(training_loader):\n",
    "        if CUDA_FLAG:\n",
    "            train_seq1 = train_seq1.cuda()\n",
    "            train_seq2 = train_seq2.cuda()\n",
    "            train_target = train_target.cuda()\n",
    "        train_seq1 = Variable(train_seq1)\n",
    "        train_seq2 = Variable(train_seq2)\n",
    "        train_target = Variable(train_target).float()\n",
    "        train_output1, train_output2 = net(train_seq1, train_seq2)\n",
    "        train_loss_contrastive = criterion(train_output1, train_output2, train_target)\n",
    "        #train_running_loss += train_loss_contrastive.data[0]\n",
    "        train_running_loss += train_loss_contrastive.item()\n",
    "        \n",
    "        if batch_index % train_batch_interval == train_batch_interval - 1:\n",
    "            print('Epoch: {:d}/{:d}, Batch: {:d}/{:d}\\n'\n",
    "                  'Accumulated loss: {:.4e}'.format(\n",
    "                  epoch + 1, Config.num_epoch, \n",
    "                  batch_index + 1, train_num_batch, \n",
    "                  train_running_loss / (batch_index + 1)))\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        train_loss_contrastive.backward()\n",
    "        optimizer.step() \n",
    "    train_loss = train_running_loss / train_num_batch\n",
    "    train_loss_hist.append(train_loss)\n",
    "    print('Train loss: {:.4e}'.format(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss():\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(train_loss_hist[1:], 'b')\n",
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_dist(embedding1, embedding2):\n",
    "    return 1 - np.sum(np.minimum(embedding1, embedding2)) / np.sum(np.maximum(embedding1, embedding2)) \n",
    "    \n",
    "def pair_dist(fp, N, embedding_fp, dist_fp):\n",
    "    seq = torch.zeros((N, 4, SEQ_LEN))\n",
    "    cnt = 0\n",
    "    seq_ids = []\n",
    "    with open(fp) as f:\n",
    "        while True:\n",
    "            next_n = list(islice(f, 2))\n",
    "            if not next_n:\n",
    "                break\n",
    "            seq_id = next_n[0].strip()[1:]\n",
    "            read = next_n[1].strip()\n",
    "            seq_ids.append(seq_id)\n",
    "            for i, c in enumerate(read):\n",
    "                seq[cnt, atcg_map.get(c, 0), i] = 1.0\n",
    "            cnt += 1\n",
    "    embeddings = net.forward_one_side(Variable(seq)).data.numpy()\n",
    "    embeddings.tofile(embedding_fp, sep=',', format='%.4e')\n",
    "    with open(dist_fp, 'w') as fo:\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i < j:\n",
    "                    fo.write('{}-{}\\t{:.4f}\\n'.format(\n",
    "                        seq_ids[i], seq_ids[j],\n",
    "                        jaccard_dist(embeddings[i],\n",
    "                                     embeddings[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def my_plot(align_dist_df, x_dist_df, save_fp):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    vmin = align_dist_df[1].min()\n",
    "    vmax = align_dist_df[1].max()\n",
    "    percentile = 99\n",
    "\n",
    "    hb = ax.hexbin(\n",
    "        align_dist_df[1],\n",
    "        x_dist_df[1],\n",
    "        gridsize=200,\n",
    "        bins='log',\n",
    "        cmap='Blues',\n",
    "        extent=(0, 1, 0, 1),\n",
    "        norm=plt.Normalize(vmin=np.percentile(align_dist_df[1], 100 - percentile),\n",
    "                           vmax=np.percentile(align_dist_df[1], percentile))\n",
    "    )\n",
    "\n",
    "    ax.plot(np.linspace(0, 1, 100), np.linspace(0, 1, 100), 'r')\n",
    "    ax.set_xlabel('alignment distance', fontsize=20)\n",
    "    ax.set_ylabel('SENSE', fontsize=20)\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.95, 0.1, 0.05, 0.8])\n",
    "    cbar_ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    cbar = fig.colorbar(hb, cax=cbar_ax)\n",
    "    cbar.set_label('log10(count + 1)', fontsize=20)\n",
    "    fig.savefig(save_fp, bbox_inches='tight')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "NUM_EVAL_N = 500 # number of eval pairs is N*(N-1)/2\n",
    "pair_dist('./demo/eval.fa', NUM_EVAL_N, './demo/embeddings.txt', './demo/embeddings_dist.txt')\n",
    "nw_df = pd.read_csv('./demo/eval_dist.txt', sep='\\t', header=None)\n",
    "my_df = pd.read_csv('./demo/embeddings_dist.txt', sep='\\t', header=None)\n",
    "my_plot(nw_df, my_df, save_fp='./demo/demo.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def tensor_to_atcg(tensor):\n",
    "    atcg = \"ATCG\"\n",
    "    return \"\".join([atcg[i] for i in tensor.argmax(dim=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Brute force con pairwise -Funziona\n",
    "import time\n",
    "import csv\n",
    "\n",
    "csv_data = []\n",
    "\n",
    "start_vero = time.time()\n",
    "fasta = './demo/pair_shuffle.fa'\n",
    "sequences = [str(record.seq) for record in SeqIO.parse(fasta, \"fasta\")]\n",
    "#sequences = random.sample(all_sequences, 500)\n",
    "#print(len(sequences))\n",
    "\n",
    "# Effettua l'allineamento per ogni sequenza rispetto a tutte le altre sequenze\n",
    "#for i in range(len(sequences)):\n",
    "for i in range(60):\n",
    "    start_time = time.time()\n",
    "    seq1_embedding = net.get_embedding(sequences[i])\n",
    "\n",
    "    # Inizializza le variabili per il punteggio migliore e la sequenza corrispondente\n",
    "    best_score = float('inf')  # Inizializzato a infinito in modo che qualsiasi punteggio lo superi\n",
    "    best_sequence = \"\"\n",
    "    best_sequence_index = -1\n",
    "\n",
    "    for j in range(60):\n",
    "        if i != j:  # Evita di confrontare una sequenza con se stessa\n",
    "            seq2_embedding = net.get_embedding(sequences[j])\n",
    "\n",
    "            maxout, minout = net.align_sequences(seq1_embedding, seq2_embedding)\n",
    "\n",
    "            # Calcola la distanza di allineamento\n",
    "            alignment_distance = (minout.sum(1) / maxout.sum(1)).detach().cpu().numpy()[0]\n",
    "\n",
    "            # Aggiorna il punteggio migliore e la sequenza corrispondente se necessario\n",
    "            if alignment_distance < best_score:\n",
    "                best_score = alignment_distance\n",
    "                best_sequence = sequences[j]\n",
    "                best_sequence_index = j + 1  # Indice + 1 per ottenere il numero di sequenza\n",
    "\n",
    "    # Ottieni l'allineamento tra la sequenza corrente e quella migliore\n",
    "    alignment = pairwise2.align.globalxx(sequences[i], best_sequence, one_alignment_only=True)[0]\n",
    "    formatted_alignment = pairwise2.format_alignment(*alignment)\n",
    "\n",
    "\n",
    "    # Calcola la percentuale del numero di sequenza rispetto al totale\n",
    "    percentage = (best_sequence_index / len(sequences)) * 100\n",
    "\n",
    "    # Stampa il punteggio migliore, la sequenza corrispondente e l'allineamento per la sequenza corrente\n",
    "    print(f\"Per la sequenza {i + 1}:\")\n",
    "   \n",
    "    print(f\"Miglior punteggio di allineamento: {best_score}\")\n",
    "    print(i)\n",
    "    print(f\"Sequenza corrispondente: {best_sequence}\")\n",
    "    print(f\"Numero di sequenza corrispondente: {best_sequence_index} su {len(sequences)} (percentuale: {percentage:.2f}%)\")\n",
    "    print(f\"Allineamento:\")\n",
    "    print(formatted_alignment)\n",
    "    csv_data.append([i+1, best_sequence_index, best_sequence])\n",
    "    end_time = time.time()\n",
    "    tempo_effettivo = end_time - start_time\n",
    "    print(tempo_effettivo)\n",
    "\n",
    "# Scrivi i risultati in un file csv\n",
    "with open('bruteforce.csv', 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['index', 'best_sequence_index', 'best_sequence'])\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "tempo_finale = time.time() - start_vero\n",
    "print(tempo_finale)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#allineamento genetico senza pairwise - Deprecato, utile per funzionamento a scopo di prova\n",
    "def global_alignment(seq1, seq2, match_score=1, mismatch_score=-1, gap_penalty=-1):\n",
    "    len_seq1, len_seq2 = len(seq1), len(seq2)\n",
    "\n",
    "    # Inizializza una matrice per memorizzare i punteggi dell'allineamento\n",
    "    alignment_matrix = [[0] * (len_seq2 + 1) for _ in range(len_seq1 + 1)]\n",
    "\n",
    "    # Inizializza la prima colonna e la prima riga\n",
    "    for i in range(len_seq1 + 1):\n",
    "        alignment_matrix[i][0] = i * gap_penalty\n",
    "\n",
    "    for j in range(len_seq2 + 1):\n",
    "        alignment_matrix[0][j] = j * gap_penalty\n",
    "\n",
    "    # Calcola i punteggi dell'allineamento riempiendo la matrice\n",
    "    for i in range(1, len_seq1 + 1):\n",
    "        for j in range(1, len_seq2 + 1):\n",
    "            match = alignment_matrix[i - 1][j - 1] + (match_score if seq1[i - 1] == seq2[j - 1] else mismatch_score)\n",
    "            delete = alignment_matrix[i - 1][j] + gap_penalty\n",
    "            insert = alignment_matrix[i][j - 1] + gap_penalty\n",
    "\n",
    "            alignment_matrix[i][j] = max(match, delete, insert)\n",
    "\n",
    "    # Risaliamo dalla fine della matrice per ricostruire l'allineamento\n",
    "    aligned_seq1, aligned_seq2 = \"\", \"\"\n",
    "    i, j = len_seq1, len_seq2\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        current_score = alignment_matrix[i][j]\n",
    "\n",
    "        if i > 0 and alignment_matrix[i - 1][j] + gap_penalty == current_score:\n",
    "            aligned_seq1 = seq1[i - 1] + aligned_seq1\n",
    "            aligned_seq2 = \"-\" + aligned_seq2\n",
    "            i -= 1\n",
    "        elif j > 0 and alignment_matrix[i][j - 1] + gap_penalty == current_score:\n",
    "            aligned_seq1 = \"-\" + aligned_seq1\n",
    "            aligned_seq2 = seq2[j - 1] + aligned_seq2\n",
    "            j -= 1\n",
    "        else:\n",
    "            aligned_seq1 = seq1[i - 1] + aligned_seq1\n",
    "            aligned_seq2 = seq2[j - 1] + aligned_seq2\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "\n",
    "    return aligned_seq1, aligned_seq2\n",
    "    \n",
    "def format_alignment(seq1, seq2):\n",
    "    line_length = 80  # Lunghezza massima della riga per facilitare la lettura\n",
    "    lines = []\n",
    "    for i in range(0, len(seq1), line_length):\n",
    "            seq1_line = seq1[i:i + line_length]\n",
    "            seq2_line = seq2[i:i + line_length]\n",
    "    \n",
    "            match_line = \"\".join(\"|\" if base1 == base2 else \" \" for base1, base2 in zip(seq1_line, seq2_line))\n",
    "    \n",
    "            lines.append(f\"{seq1_line}\\n{match_line}\\n{seq2_line}\\n\\n\")\n",
    "    \n",
    "    return \"\".join(lines)\n",
    "\n",
    "start1 = time.time()\n",
    "\n",
    "# Inizializza il toolbox\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Leggi sequenze genomiche da un file FASTA\n",
    "input_file = './converted/pair_shuffle.fa'\n",
    "#num_sequences_to_select = 500\n",
    "\n",
    "# Leggi tutte le sequenze dal file .fa\n",
    "all_sequences = list(SeqIO.parse(input_file, \"fasta\"))\n",
    "\n",
    "# Seleziona casualmente 500 sequenze\n",
    "#selected_sequences = random.sample(all_sequences, num_sequences_to_select)\n",
    "#print(len(selected_sequences))\n",
    "\n",
    "current_sequence_index = 0\n",
    "\n",
    "def generate_individual():\n",
    "    global current_sequence_index\n",
    "    if current_sequence_index + 1 >= len(all_sequences):\n",
    "        # Se tutte le sequenze sono state utilizzate, reimposta l'indice\n",
    "        current_sequence_index = 0\n",
    "\n",
    "    # Seleziona due sequenze consecutive\n",
    "    seq1 = str(all_sequences[current_sequence_index].seq)\n",
    "    seq2 = str(all_sequences[current_sequence_index + 1].seq)\n",
    "\n",
    "    # Incrementa l'indice per la prossima chiamata\n",
    "    current_sequence_index += 2\n",
    "\n",
    "    return [seq1, seq2]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Crea una funzione per generare una coppia di sequenze genomiche\n",
    "def generate_individual():\n",
    "return random.sample(all_sequences, 2)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Inizializza il toolbox\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, generate_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "#toolbox.register(\"mate\", crosseSubsequence)\n",
    "toolbox.register(\"mutate\", crosseSubsequence)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=5)\n",
    "\n",
    "net = SiameseNetwork()\n",
    "\n",
    "def crosseSubsequence(individual):\n",
    "    # Seleziona due sequenze casuali dall'individuo\n",
    "    seq1, seq2 = individual[0][0],individual[0][1]\n",
    "\n",
    "    # Esegui il crossover (definisci la tua logica di crossover)\n",
    "    start_position = random.randint(0, min(len(seq1), len(seq2)) - 1)\n",
    "    subset_size = random.randint(1, min(len(seq1) - start_position, len(seq2) - start_position))\n",
    "\n",
    "    # Scambia le sottosequenze tra seq1 e seq2\n",
    "    seq1_mutated = seq1[:start_position] + seq2[start_position:start_position + subset_size] + seq1[start_position + subset_size:]\n",
    "    seq2_mutated = seq2[:start_position] + seq1[start_position:start_position + subset_size] + seq2[start_position + subset_size:]\n",
    "\n",
    "    # Restituisci la coppia crossoverata come unico individuo\n",
    "    return [seq1_mutated,seq2_mutated]\n",
    "# Definisci la funzione di fitness che calcola la distanza tra le sequenze\n",
    "def evaluate(individual):\n",
    "    \n",
    "    \n",
    "    seq1, seq2 = individual[0][0],individual[0][1]# Ottieni le sequenze da SeqRecord\n",
    "    seq1_embedding = net.get_embedding(seq1)\n",
    "    seq2_embedding = net.get_embedding(seq2)\n",
    "    maxout, minout = net.align_sequences(seq1_embedding, seq2_embedding)\n",
    "    distance = maxout.sum(1) / minout.sum(1)\n",
    "    return distance.item(),\n",
    "\n",
    "\n",
    "\n",
    "# Imposta il numero di generazioni e la dimensione della popolazione\n",
    "generations = 10\n",
    "population_size = 200\n",
    "popolazioni = 1\n",
    "for i in range(popolazioni):\n",
    "    print(f\"\\nRun {i + 1}:\")\n",
    "    # Esegui l'algoritmo genetico 10 volte\n",
    "    for run in range(1):\n",
    "        \n",
    "        # Crea una popolazione iniziale\n",
    "        pop = toolbox.population(n=population_size)\n",
    "    \n",
    "        # Esegui l'algoritmo genetico\n",
    "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "        stats.register(\"min\", min)\n",
    "        op, logbook = algorithms.eaSimple(pop, toolbox, cxpb=0.2, mutpb=0.2, ngen=generations, stats=stats, halloffame=None, verbose=True)\n",
    "        # Stampa la popolazione mutata alla fine di ogni generazione\n",
    "        print(f\"Generazione {gen + 1} - Popolazione Mutata:\")\n",
    "        for ind in pop:\n",
    "            print(ind)\n",
    "    \n",
    "       # Stampa il miglior individuo per ogni generazione\n",
    "        for gen in range(1):\n",
    "            best_individual = tools.selBest(pop, 1)[0]\n",
    "            best_fitness = best_individual.fitness.values[0]\n",
    "            seq1, seq2 = best_individual\n",
    "    \n",
    "            print(f\"Miglior Fitness = {best_fitness}\")\n",
    "            print(f\"Miglior coppia di sequenze:\")\n",
    "            print(f\"Seq1: {seq1.seq}\")\n",
    "            print(f\"Seq2: {seq2.seq}\")\n",
    "            alignments = global_alignment(seq1.seq, seq2.seq)\n",
    "            formatted_alignment = format_alignment(alignments[0],alignments[1])\n",
    "            print(f\"Allineamento:\")\n",
    "            print(formatted_alignment)\n",
    "    \n",
    "    print(\"\\n-------------------------------------\")\n",
    "\n",
    "end1 = time.time()\n",
    "delta = end1 - start1\n",
    "print(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Brute force senza pairwise -Funziona per allineamento e lista ordinata\n",
    "csv_data_1 = []\n",
    "\n",
    "def global_alignment(seq1, seq2, match_score=1, mismatch_score=-1, gap_penalty=-1):\n",
    "    len_seq1, len_seq2 = len(seq1), len(seq2)\n",
    "\n",
    "    # Inizializza una matrice per memorizzare i punteggi dell'allineamento\n",
    "    alignment_matrix = [[0] * (len_seq2 + 1) for _ in range(len_seq1 + 1)]\n",
    "\n",
    "    # Inizializza la prima colonna e la prima riga\n",
    "    for i in range(len_seq1 + 1):\n",
    "        alignment_matrix[i][0] = i * gap_penalty\n",
    "\n",
    "    for j in range(len_seq2 + 1):\n",
    "        alignment_matrix[0][j] = j * gap_penalty\n",
    "\n",
    "    # Calcola i punteggi dell'allineamento riempiendo la matrice\n",
    "    for i in range(1, len_seq1 + 1):\n",
    "        for j in range(1, len_seq2 + 1):\n",
    "            match = alignment_matrix[i - 1][j - 1] + (match_score if seq1[i - 1] == seq2[j - 1] else mismatch_score)\n",
    "            delete = alignment_matrix[i - 1][j] + gap_penalty\n",
    "            insert = alignment_matrix[i][j - 1] + gap_penalty\n",
    "\n",
    "            alignment_matrix[i][j] = max(match, delete, insert)\n",
    "\n",
    "    # Risaliamo dalla fine della matrice per ricostruire l'allineamento\n",
    "    aligned_seq1, aligned_seq2 = \"\", \"\"\n",
    "    i, j = len_seq1, len_seq2\n",
    "\n",
    "    while i > 0 or j > 0:\n",
    "        current_score = alignment_matrix[i][j]\n",
    "\n",
    "        if i > 0 and alignment_matrix[i - 1][j] + gap_penalty == current_score:\n",
    "            aligned_seq1 = seq1[i - 1] + aligned_seq1\n",
    "            aligned_seq2 = \"-\" + aligned_seq2\n",
    "            i -= 1\n",
    "        elif j > 0 and alignment_matrix[i][j - 1] + gap_penalty == current_score:\n",
    "            aligned_seq1 = \"-\" + aligned_seq1\n",
    "            aligned_seq2 = seq2[j - 1] + aligned_seq2\n",
    "            j -= 1\n",
    "        else:\n",
    "            aligned_seq1 = seq1[i - 1] + aligned_seq1\n",
    "            aligned_seq2 = seq2[j - 1] + aligned_seq2\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "\n",
    "    return aligned_seq1, aligned_seq2\n",
    "    \n",
    "def format_alignment(seq1, seq2):\n",
    "    line_length = 80  # Lunghezza massima della riga per facilitare la lettura\n",
    "    lines = []\n",
    "    for i in range(0, len(seq1), line_length):\n",
    "            seq1_line = seq1[i:i + line_length]\n",
    "            seq2_line = seq2[i:i + line_length]\n",
    "    \n",
    "            match_line = \"\".join(\"|\" if base1 == base2 else \" \" for base1, base2 in zip(seq1_line, seq2_line))\n",
    "    \n",
    "            lines.append(f\"{seq1_line}\\n{match_line}\\n{seq2_line}\\n\\n\")\n",
    "    \n",
    "    return \"\".join(lines)\n",
    "\n",
    "start_vero = time.time()\n",
    "fasta = './demo/pair_shuffle.fa'\n",
    "sequences_all = [str(record.seq) for record in SeqIO.parse(fasta, \"fasta\")]\n",
    "sequences=sequences_all[:500]\n",
    "print(len(sequences))\n",
    "\n",
    "# Inizializza un insieme di sequenze utilizzate\n",
    "used_sequences = set()\n",
    "\n",
    "# Lista per tenere traccia della catena delle sequenze ordinate decrescenti\n",
    "ordered_sequence_chain = []\n",
    "iterazioni = 20\n",
    "print(iterazioni)\n",
    "\n",
    "for i in range(20):\n",
    "    start_time = time.time()\n",
    "    # Seleziona la sequenza corrente come punto di partenza\n",
    "    current_sequence_index = 0\n",
    "    current_2 = 1\n",
    "    prima_sequenza = sequences[current_sequence_index]\n",
    "    print(prima_sequenza)\n",
    "    current_sequence = sequences[current_2]\n",
    "\n",
    "    # Se la sequenza è già stata utilizzata, passa alla prossima iterazione\n",
    "    if current_2 in used_sequences:\n",
    "        continue\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Inizializza le variabili per il punteggio migliore e la sequenza corrispondente\n",
    "    best_score = 0  # Inizializzato a infinito in modo che qualsiasi punteggio lo superi\n",
    "    best_sequence = \"\"\n",
    "    best_sequence_index = -1\n",
    "\n",
    "    for j in range(len(sequences)):\n",
    "        if current_sequence_index != j and j not in used_sequences:\n",
    "            seq1_embedding = net.get_embedding(prima_sequenza)\n",
    "            seq2_embedding = net.get_embedding(sequences[j])\n",
    "\n",
    "            maxout, minout = net.align_sequences(seq1_embedding, seq2_embedding)\n",
    "\n",
    "            alignment_distance = (minout.sum(1) / maxout.sum(1)).detach().cpu().numpy()[0]\n",
    "\n",
    "            if alignment_distance > best_score:\n",
    "                best_score = alignment_distance\n",
    "                best_sequence = sequences[j]\n",
    "                best_sequence_index = j\n",
    "\n",
    "    # Aggiungi la sequenza corrente all'insieme delle sequenze utilizzate\n",
    "    used_sequences.add(current_sequence)\n",
    "\n",
    "    # Rimuovi la sequenza corrispondente dalla lista delle sequenze totali\n",
    "    sequences.pop(best_sequence_index)\n",
    "    print(best_sequence_index)\n",
    "\n",
    "    # Ottieni l'allineamento tra la sequenza corrente e quella migliore\n",
    "    alignments = global_alignment(current_sequence, best_sequence)\n",
    "    \n",
    "    if alignments:\n",
    "        alignment = alignments[0]\n",
    "        formatted_alignment = format_alignment(alignments[0],alignments[1])\n",
    "\n",
    "    # Calcola la percentuale del numero di sequenza rispetto al totale\n",
    "    percentage = (best_sequence_index + 1) / len(sequences) * 100\n",
    "\n",
    "    # Stampa il punteggio migliore, la sequenza corrispondente e l'allineamento per la sequenza corrente\n",
    "    print(f\"Per la sequenza {current_sequence_index + 1}:\")\n",
    "    print(f\"Miglior punteggio di allineamento: {best_score}\")\n",
    "    print(f\"Sequenza corrispondente: {best_sequence}\")\n",
    "    print(f\"Numero di sequenza corrispondente: {best_sequence_index + 1} su {len(sequences)} (percentuale: {percentage:.2f}%)\")\n",
    "    print(f\"Allineamento:\")\n",
    "    print(formatted_alignment)\n",
    "    end_time = time.time()\n",
    "    tempo_effettivo = end_time - start_time\n",
    "    print(f\"Tempo effettivo: {tempo_effettivo:.2f} secondi\")\n",
    "    csv_data_1.append([i+1, best_sequence_index, best_sequence])\n",
    "    print()\n",
    "\n",
    "    # Aggiungi la sequenza corrente alla catena delle sequenze ordinate decrescenti\n",
    "    ordered_sequence_chain.append(current_sequence)\n",
    "\n",
    "    # Aggiungi la sequenza migliore alla catena delle sequenze ordinate decrescenti\n",
    "    ordered_sequence_chain.append(best_sequence)\n",
    "\n",
    "tempo_finale = time.time() - start_vero\n",
    "print(f\"Tempo totale: {tempo_finale:.2f} secondi\")\n",
    "# Scrivi i risultati in un file csv\n",
    "with open('bruteforce.csv', 'w', newline='') as csv_file:     \n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['index', 'best_sequence_index', 'best_sequence'])\n",
    "    writer.writerows(csv_data_1)\n",
    "\n",
    "# Stampa la catena delle sequenze ordinate decrescenti\n",
    "print(\"Catena delle sequenze ordinate decrescenti:\")\n",
    "for idx, sequence in enumerate(ordered_sequence_chain):\n",
    "    print(f\"Sequenza {idx + 1}: {sequence}\")\n",
    "tempo_finale = time.time() - start_vero\n",
    "print(tempo_finale)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def pair_dist(fp, N, embedding_fp, dist_fp):\n",
    "    seq = torch.zeros((N, 4, SEQ_LEN))\n",
    "    cnt = 0\n",
    "    seq_ids = []\n",
    "    with open(fp) as f:\n",
    "        while True:\n",
    "            next_n = list(islice(f, 2))\n",
    "            if not next_n:\n",
    "                break\n",
    "            seq_id = next_n[0].strip()[1:]\n",
    "            read = next_n[1].strip()\n",
    "            seq_ids.append(seq_id)\n",
    "            for i, c in enumerate(read):\n",
    "                seq[cnt, atcg_map.get(c, 0), i] = 1.0\n",
    "            cnt += 1\n",
    "    embeddings = net.forward_one_side(Variable(seq)).data.numpy()\n",
    "    embeddings.tofile(embedding_fp, sep=',', format='%.4e')\n",
    "    with open(dist_fp, 'w') as fo:\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                if i < j:\n",
    "                    fo.write('{}-{}\\t{:.4f}\\n'.format(\n",
    "                        seq_ids[i], seq_ids[j],\n",
    "                        jaccard_dist(embeddings[i],\n",
    "                                     embeddings[j])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def confronta_sequenze(seq1, seq2):\n",
    "    lunghezza = min(len(seq1), len(seq2))\n",
    "    corrispondenze = sum(a == b for a, b in zip(seq1, seq2))\n",
    "    percentuale_corrispondenza = (corrispondenze / lunghezza) * 100    \n",
    "    return percentuale_corrispondenza\n",
    "    \n",
    "def leggi_csv(file_path):\n",
    "    sequenze = {}    \n",
    "    with open(file_path, 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        header = next(csv_reader)\n",
    "        for row in csv_reader:\n",
    "            indice, _, sequenza = row            \n",
    "            sequenze[indice] = sequenza\n",
    "    return sequenze\n",
    "    \n",
    "file_brute = 'bruteforce.csv'\n",
    "file_genetic = 'genetico.csv'\n",
    "output_file = 'risultati_confronto.csv'\n",
    "sequenze_brute = leggi_csv(file_brute)\n",
    "sequenze_genetic = leggi_csv(file_genetic)\n",
    "risultati = []\n",
    "for indice in sequenze_brute:\n",
    "    if indice in sequenze_genetic:\n",
    "        seq_brute = sequenze_brute[indice]\n",
    "        seq_genetic = sequenze_genetic[indice]\n",
    "        percentuale = confronta_sequenze(seq_brute, seq_genetic)\n",
    "        risultati.append((indice, percentuale))\n",
    "\n",
    "with open(output_file, 'w', newline='') as file:\n",
    "    csv_writer = csv.writer(file)\n",
    "    csv_writer.writerow(['indice', 'percentuale_corrispondenza'])\n",
    "    csv_writer.writerows(risultati)\n",
    "   \n",
    "print(f'Risultati salvati in: {output_file}')\n",
    "percentuali_totali = [percentuale for _, percentuale in risultati]\n",
    "percentuale_totale_media = sum(percentuali_totali) /len(percentuali_totali) if percentuali_totali else 0\n",
    "print(f'Percentuale totale media: {percentuale_totale_media:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
